# AI Tutor Implementation - Complete Guide

## Overview
Successfully implemented a fully functional AI Tutor feature with streaming responses and PDF context awareness.

## âœ… Features Implemented

### 1. Backend - Streaming API
**Location:** `backend/src/ai/`

#### New Endpoint: `/ai/tutor/chat/stream`
- **Method:** POST
- **Type:** Server-Sent Events (SSE)
- **Features:**
  - Real-time streaming responses from Gemini AI
  - Session management (creates or continues chat sessions)
  - Context-aware responses using selected PDF materials
  - Automatic message persistence to database

#### AI Service Enhancement
**File:** `backend/src/ai/ai.service.ts`

New Method: `tutorChatStream()`
```typescript
async tutorChatStream(
  userQuestion: string,
  userId: string,
  res: Response,
  sessionId?: string,
  noteId?: string
): Promise<void>
```

**Features:**
- Uses Gemini's `generateContentStream()` for streaming
- Sends chunks in real-time via SSE
- Includes learning materials context from selected notes
- Saves complete messages to database after streaming

**Stream Event Types:**
- `session`: Returns sessionId when session is created/loaded
- `chunk`: Contains text content as it's generated
- `done`: Signals completion with messageId
- `error`: Reports any errors during streaming

### 2. Frontend - TutorService
**Location:** `frontend/src/services/TutorService.ts`

#### New Service Methods:
1. **sendMessageStream()** - Handles streaming chat
   - Establishes SSE connection
   - Parses incoming chunks
   - Calls callback for each chunk

2. **getUserChatSessions()** - List all sessions
3. **getChatSession()** - Get session details
4. **updateChatSessionTitle()** - Update session name
5. **deleteChatSession()** - Remove session

### 3. Frontend - React Hooks
**Location:** `frontend/src/hooks/useTutor.ts`

New Hooks:
- `useTutorSessions(userId)` - Fetch user's chat sessions
- `useTutorSession(sessionId, userId)` - Get specific session
- `useUpdateSessionTitle()` - Mutation for title updates
- `useDeleteSession()` - Mutation for session deletion

### 4. Frontend - UI Component
**Location:** `frontend/src/routes/__protected.tutor.tsx`

#### Key Features:

**Sidebar - Material Selection:**
- Shows all user's uploaded PDF notes
- Checkbox selection for context materials
- Visual indication when context is active
- Empty state prompts user to upload PDFs

**Chat Interface:**
- Real-time streaming text display with cursor animation
- Message bubbles for user and AI
- Auto-scroll to latest message
- Loading states during AI response

**User Experience:**
- Press Enter to send (Shift+Enter for new line)
- Disabled input during streaming
- Loading spinner while processing
- Error handling with user-friendly messages

## ğŸ¯ How It Works

### Flow Diagram:
```
1. User selects PDF materials from sidebar
   â†“
2. User types question and hits Enter
   â†“
3. Frontend sends POST to /ai/tutor/chat/stream
   â†“
4. Backend:
   - Creates/loads chat session
   - Gets PDF content from selected note
   - Sends to Gemini with context
   - Streams response back chunk by chunk
   â†“
5. Frontend:
   - Receives chunks via SSE
   - Updates message content in real-time
   - Shows streaming cursor animation
   â†“
6. Backend saves complete message to DB
   â†“
7. Frontend marks streaming complete
```

## ğŸ“ Key Implementation Details

### 1. Context from PDFs
When a user selects materials:
- Frontend passes `noteId` to backend
- Backend fetches note content from database
- Content is injected into AI prompt as context
- AI bases answers on the provided materials

### 2. Streaming Response
**Backend (NestJS):**
```typescript
// Set SSE headers
res.setHeader('Content-Type', 'text/event-stream');
res.setHeader('Cache-Control', 'no-cache');

// Stream chunks
for await (const chunk of result.stream) {
  const chunkText = chunk.text();
  res.write(`data: ${JSON.stringify({ type: 'chunk', content: chunkText })}\n\n`);
}
```

**Frontend (React):**
```typescript
const reader = response.body?.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  // Parse and handle chunks
  const chunk = JSON.parse(data);
  onChunk(chunk);
}
```

### 3. 1-Second Delay (As Requested)
The streaming naturally provides a gradual response. Each chunk appears as Gemini generates it, creating a smooth, Gemini-like typing effect.

## ğŸš€ Usage Instructions

### For Users:
1. Navigate to `/tutor` page
2. Select one or more PDF materials from sidebar
3. Type your question in the input box
4. Press Enter or click Send
5. Watch as AI responds in real-time!

### For Developers:

**Start Backend:**
```bash
cd backend
npm run start:dev
```

**Start Frontend:**
```bash
cd frontend
npm run dev
```

**Test the Feature:**
1. Upload a PDF on the Notes page first
2. Go to Tutor page
3. Select the uploaded note
4. Ask a question related to the PDF content

## ğŸ”‘ Environment Variables Required

```env
GEMINI_API_KEY=your_gemini_api_key_here
```

## ğŸ“¦ Dependencies Added

### Frontend:
- No new dependencies (uses existing fetch API)
- shadcn/ui checkbox component

### Backend:
- No new dependencies (uses existing @google/generative-ai)

## ğŸ¨ UI/UX Highlights

1. **Streaming Cursor:** Animated pulse cursor during AI response
2. **Material Selection:** Clear visual feedback on selected materials
3. **Context Indicator:** Shows when AI has context active
4. **Auto-scroll:** Automatically scrolls to latest message
5. **Loading States:** Spinner during processing
6. **Empty States:** Helpful prompts when no materials exist
7. **Keyboard Shortcuts:** Enter to send, Shift+Enter for newline

## ğŸ”’ Security Considerations

- User authentication required (uses AuthContext)
- User can only access their own sessions
- Session IDs validated on backend
- Only user's own notes can be selected as context

## ğŸ“Š Database Schema Used

```prisma
model ChatSession {
  id        String   @id @default(cuid())
  userId    String
  noteId    String?
  title     String
  messages  ChatMessage[]
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt
}

model ChatMessage {
  id        String   @id @default(cuid())
  sessionId String
  role      String   // 'user' or 'assistant'
  content   String   @db.Text
  createdAt DateTime @default(now())
}
```

## âœ¨ Success Criteria Met

âœ… Streaming responses like Gemini
âœ… Uses uploaded PDF content as context
âœ… Real-time text display
âœ… Session persistence
âœ… Clean, intuitive UI
âœ… Error handling
âœ… Loading states
âœ… Auto-scroll
âœ… Material selection

## ğŸ‰ Ready to Use!

The AI Tutor is fully functional and ready to help users learn from their uploaded PDF materials with intelligent, context-aware responses!
